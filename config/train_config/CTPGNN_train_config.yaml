#This is an example of train_config.yaml

# basic
random_seed: 666
batch_size: 50
device: cuda:0
load_checkpoint: False

# Optimizer
optimizer_name: Adam
optimizer_params:
  lr: 0.001
  weight_decay: 0.0001

# Scheduler
scheduler_name: MultiStepLR
scheduler_params:
  milestones: [5, 20, 40, 70]
  gamma: 0.3

# Trainer
trainer_name: CTPGNNTrainer
trainer_params:
  resume: False
  max_epoch_num: 10
  early_stop: 10
  train_TPGNN_epochs: 10
  train_TPGNN_optimizer_name: Adam
  train_TPGNN_optimizer_params:
    lr: 0.001
    weight_decay: 0.0001
